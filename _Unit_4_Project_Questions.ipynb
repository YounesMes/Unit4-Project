{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YounesMes/Unit4-Project/blob/master/_Unit_4_Project_Questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcBqRLqzMULW"
      },
      "source": [
        "# Unit 4 Project\n",
        "After understanding how neural networks work, implementing some basic architectures using deep learning frameworks, and learning about some advanced techniques to help enhance our neural networks' models results, it's time to apply what you learned! So let's start\n",
        "\n",
        "## Project Overview \n",
        "In this project, you will build a neural network model to classify images from CIFAR 10 dataset. \n",
        "\n",
        "The CIFAR-10 dataset consists of 60000 32x32 color images of 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. [source](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "\n",
        "Unlike the previous projects, there will be no code cells to fill, the only task you have is to build the best possible model using the techniques you learned about in this unit. But we will guide you with some directives.\n",
        "\n",
        "You will have enough guidance throughout the project and your work will be reviewed and graded by a teacher assistant. You can also reach out to the TA via slack whenever you feel you are stuck.\n",
        "\n",
        "## Some guidelines\n",
        "- Please use text cells to write the questions' answers in a good way.\n",
        "- Don't forget to save the different models you tested so you will be able to report the different results you got and the impact of the different techniques you tested later.\n",
        "\n",
        "## Getting started\n",
        "- In case you don't have a GPU, it is recommended that you use google colab. Start by cloning this repository, then open [google colab](https://colab.research.google.com/), click on File > Upload notebook, and finally upload the ```.ipynb``` file from the repository you have just cloned! Don't forget to change the runtime to GPU. If you want to work in your local environment just open it using jupyter notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLavLevW45rD"
      },
      "source": [
        "## Dataset \n",
        "\n",
        "1.   Load the dataset (**hint**: it's available here https://keras.io/api/datasets/)\n",
        "2.   Display few images of each class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7D9q0qVMj98"
      },
      "outputs": [],
      "source": [
        "#importing librairies\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "from matplotlib.pyplot import imshow\n",
        "from tensorflow.keras import datasets, layers, Input,models\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "from keras import regularizers\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import pickle as pk\n",
        "import seaborn as sn\n",
        "import io\n",
        "import datetime\n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjCuHlIcdsp5",
        "outputId": "59f7c1c0-2175-48e3-e8ea-d1c7ab3b7750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#importing the dataset\n",
        "import ssl\n",
        "ssl._create_default_https_context=ssl._create_unverified_context\n",
        "(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0v1jWbQNdsp7"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.reshape(-1,)\n",
        "y_train[:5]\n",
        "\n",
        "#define the classes:\n",
        "classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
        "\n",
        "def plot_simp(x,y,indx):\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.imshow(x[indx])\n",
        "    plt.xlabel(classes[y[indx]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ol2HOVFgdsp9",
        "outputId": "362f24a0-f58e-47db-890e-f3c499191eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_simp(X_train,y_train,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmIZ1vTp6pDZ"
      },
      "source": [
        "## Baseline Model\n",
        "\n",
        "1.   Build a basline model using only dense layers, activation function of your choice, and the adapted cost function for this problem.\n",
        "2.   Train and evaluate your model\n",
        "3.   Analyze the result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dj0D8kHF9_K3",
        "outputId": "3cfe80a9-4b74-4659-f722-36251b9bd982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.8166 - accuracy: 0.3526\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6250 - accuracy: 0.4263\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5468 - accuracy: 0.4554\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4851 - accuracy: 0.4774\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4370 - accuracy: 0.4953\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3943 - accuracy: 0.5102\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3550 - accuracy: 0.5251\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3180 - accuracy: 0.5369\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2865 - accuracy: 0.5505\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2585 - accuracy: 0.5579\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2277 - accuracy: 0.5698\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1986 - accuracy: 0.5798\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1699 - accuracy: 0.5907\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1449 - accuracy: 0.6000\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1184 - accuracy: 0.6115\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0911 - accuracy: 0.6196\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0662 - accuracy: 0.6289\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0371 - accuracy: 0.6396\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0133 - accuracy: 0.6489\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9886 - accuracy: 0.6579\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9632 - accuracy: 0.6666\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9375 - accuracy: 0.6755\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9117 - accuracy: 0.6846\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8847 - accuracy: 0.6949\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8602 - accuracy: 0.7056\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8352 - accuracy: 0.7117\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8093 - accuracy: 0.7234\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7860 - accuracy: 0.7317\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7600 - accuracy: 0.7412\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7332 - accuracy: 0.7497\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7121 - accuracy: 0.7578\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6834 - accuracy: 0.7705\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6581 - accuracy: 0.7786\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6358 - accuracy: 0.7860\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6144 - accuracy: 0.7934\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5887 - accuracy: 0.8025\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5676 - accuracy: 0.8110\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5426 - accuracy: 0.8198\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5188 - accuracy: 0.8287\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4949 - accuracy: 0.8376\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4784 - accuracy: 0.8427\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4555 - accuracy: 0.8526\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4313 - accuracy: 0.8603\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4096 - accuracy: 0.8691\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3928 - accuracy: 0.8746\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3715 - accuracy: 0.8838\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3506 - accuracy: 0.8907\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3318 - accuracy: 0.8996\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3195 - accuracy: 0.9010\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.2991 - accuracy: 0.9088\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f48d15af450>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Your code here\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "ann = models.Sequential([\n",
        "        layers.Flatten(input_shape=(32,32,3)),\n",
        "        layers.Dense(3000, activation='relu'),\n",
        "        layers.Dense(1000, activation='relu'),\n",
        "        layers.Dense(10, activation='sigmoid')    \n",
        "    ])\n",
        "\n",
        "ann.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ann.fit(X_train, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvygWbNy-BxD"
      },
      "source": [
        "## Accelerating the training\n",
        "\n",
        "1.   Add batch normalization layers to your network in order to accelerate the training. Start with adding batch norm layer before each of your activation layers.\n",
        "2.   Analyze the new results\n",
        "3.   Change the position of the batch norm layers so they will be after the activation layers. Compare the results.\n",
        "   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNaAVBN4-Ai4"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYXf6uM6DJ1a"
      },
      "source": [
        "## Reducing the overfitting \n",
        "\n",
        "\n",
        "1.   Apply the dropout technique to reduce the overfitting your model is suffering from\n",
        "2.   Try different dropout rates \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2er70cnXDIqI"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZkBwzPX_eHh"
      },
      "source": [
        "## Trying different model's parameters\n",
        "1. Try changing the number of layers, the number of hidden neurons in each layer, the activation functions, the weight initialization method...\n",
        "2. Compare the results you got for each evaluated model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXtHgGpjFm9i"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc8lCKMlGMrb"
      },
      "source": [
        "## Few more experiments to go\n",
        "\n",
        "1.   **Exploring more regularization techniques:** Try at least 2 regularization techniques separately and combined.  A non-exhaustive list of regularization techniques you can test\n",
        "\n",
        "\n",
        "> * L1 and L2 regularization\n",
        "* Early stopping\n",
        "* Data augmentation\n",
        "* Decreasing the complexity of the model\n",
        "\n",
        "2.   **Hyperparameters' tuning:** Try to tune the learning parameters using the tuning strategies we learned about:\n",
        "\n",
        "> * Learning rate\n",
        "* Mini-batch size\n",
        "* The optimizer and its parameters\n",
        "\n",
        "3. Analyze the impact of each of the applied techniques. What were the most effective ones? What were the hypeparameters that affects the results the most?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBXIjaAVGMPd"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcFRgyd_TAOx"
      },
      "source": [
        "## Answer the following questions\n",
        "*Hint: Do your own research to answer these questions, none of the questions is answered in the previous lessons*\n",
        "\n",
        "\n",
        "1.   Why we can’t reach a good accuracy on this task?\n",
        "2.   Explain why fully connected neural networks are Not efficient on image tasks\n",
        "3.   What architecture can be used  for such tasks? Why they are more adapted for that?\n",
        "\n",
        "\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COtGbMoHUdsC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copie de Unit 4 Project - Questions.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}